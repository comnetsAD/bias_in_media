{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import os\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''\n",
    "\n",
    "def get_posters(data, year, language):\n",
    "    for movie in data['results']:\n",
    "        try:\n",
    "            poster_path = 'https://image.tmdb.org/t/p/w1280/' + movie['poster_path']\n",
    "            if language == 'hi|kn|ml|ta|te':\n",
    "                language = 'indian'\n",
    "            elif language == 'zh|cn':\n",
    "                language = 'chinese'\n",
    "                \n",
    "            os.makedirs(f'../data/global_posters/{language}/{year}', exist_ok=True)\n",
    "            save_path = f'../data/global_posters/{language}/{year}/{movie[\"id\"]}.jpg'\n",
    "            urllib.request.urlretrieve(poster_path, save_path)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "def get_page(page, language, year):\n",
    "    request = f'https://api.themoviedb.org/3/discover/movie?api_key={API_KEY}&sort_by=popularity.desc&page={page}&primary_release_year={year}&with_original_language={language}'\n",
    "    r = requests.get(request)\n",
    "    data = r.json()\n",
    "    get_posters(data, year, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in ['es', 'pt', 'hi|kn|ml|ta|te', 'ja', 'de', 'zh|cn', 'tr', 'fa', 'fr', 'en', 'ar']:\n",
    "    print(language)\n",
    "    year = 1950\n",
    "    page = 1\n",
    "    request = f'https://api.themoviedb.org/3/discover/movie?api_key={API_KEY}&sort_by=popularity.desc&page={page}&primary_release_year={year}&with_original_language={language}'\n",
    "    r = requests.get(request)\n",
    "    data = r.json()\n",
    "    get_posters(data, year, language)\n",
    "\n",
    "    max = 10\n",
    "    if data['total_pages'] < max:\n",
    "        max = data['total_pages']\n",
    "                                \n",
    "    Parallel(n_jobs = 10)(delayed(get_page)(page, language, year) for page in range(2, max + 1))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre(id, year):\n",
    "    try:\n",
    "        request = f'https://api.themoviedb.org/3/movie/{id}?api_key={API_KEY}'\n",
    "        r = requests.get(request)\n",
    "        data = r.json()\n",
    "        ids = []\n",
    "        genres = []\n",
    "        \n",
    "        for genre in data['genres']:\n",
    "            ids.append(id)\n",
    "            genres.append(genre['name'])\n",
    "            \n",
    "        temp = pd.DataFrame({'id': ids, 'genre': genres})\n",
    "        path = f'../data/fashion_movie_data/{year}_poster_genres.csv'\n",
    "        df = pd.read_csv(path)\n",
    "        df = pd.concat([df, temp])\n",
    "        df.to_csv(path, index = False)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "def get_year(year, path):\n",
    "    if year == '.DS_Store':\n",
    "        return\n",
    "    print(year)\n",
    "    df = pd.DataFrame({'id': [], 'genre': []})\n",
    "    p = f'../data/fashion_movie_data/{year}_poster_genres.csv'\n",
    "    df.to_csv(p, index=False)\n",
    "    \n",
    "    new_path = path + year + '/'\n",
    "    ids = os.listdir(new_path)\n",
    "    ids = [int(i.split('.')[0]) for i in ids]\n",
    "    for id in ids:\n",
    "        get_genre(id, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975\n",
      "20132023\n",
      "1988202220121981\n",
      "\n",
      "\n",
      "2024\n",
      "\n",
      "\n",
      "2014\n",
      "2015\n",
      "1972\n",
      "1986\n",
      "1987\n",
      "1973\n",
      "1974\n",
      "1980\n",
      "1989\n",
      "1958\n",
      "1993\n",
      "1967\n",
      "1960\n",
      "1994\n",
      "1969\n",
      "1956\n",
      "1951\n",
      "1968\n",
      "1957\n",
      "1995\n",
      "1961\n",
      "1959\n",
      "1966\n",
      "1992\n",
      "2008\n",
      "2001\n",
      "2006\n",
      "2007\n",
      "2000\n",
      "2009\n",
      "2017\n",
      "2010\n",
      "2019\n",
      "2021\n",
      "2020\n",
      "2018\n",
      "2011\n",
      "2016\n",
      "1978\n",
      "1971\n",
      "1985\n",
      "1982\n",
      "1976\n",
      "1977\n",
      "1983\n",
      "1984\n",
      "1970\n",
      "1979\n",
      "1963\n",
      "1997\n",
      "1990\n",
      "1964\n",
      "1999\n",
      "1952\n",
      "1955\n",
      "1954\n",
      "1998\n",
      "1953\n",
      "1965\n",
      "1991\n",
      "1996\n",
      "1962\n",
      "2005\n",
      "2002\n",
      "2003\n",
      "2004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/global_posters/english/'\n",
    "us_year = os.listdir(path)\n",
    "\n",
    "Parallel(n_jobs = 10)(delayed(get_year)(year, path) for year in us_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
